{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the world where fashion meets computer vision! This is a starter kernel that applies Mask R-CNN with COCO pretrained weights to the task of [iMaterialist (Fashion) 2019 at FGVC6](https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('/home/ubuntu/efs/kaggle/imaterialist/')\n",
    "ROOT_DIR = Path('/home/ubuntu/efs/kaggle/imaterialist/maskrcnn/logs')\n",
    "\n",
    "# For demonstration purpose, the classification ignores attributes (only categories),\n",
    "# and the image size is set to 512, which is the same as the size of submission masks\n",
    "NUM_CATS = 46\n",
    "IMAGE_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/efs/kaggle/imaterialist/maskrcnn/logs/Mask_RCNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "print(ROOT_DIR/'Mask_RCNN')\n",
    "sys.path.append(\"/home/ubuntu/github/Mask_RCNN/\")\n",
    "#sys.path.append(ROOT_DIR/'Mask_RCNN')\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask R-CNN has a load of hyperparameters. I only adjust some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_META_SIZE                59\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              none\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           fashion\n",
      "NUM_CLASSES                    47\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (16, 32, 64, 128, 256)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class FashionConfig(Config):\n",
    "    NAME = \"fashion\"\n",
    "    NUM_CLASSES = NUM_CATS + 1 # +1 for the background class\n",
    "    \n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1 # a memory error occurs when IMAGES_PER_GPU is too high\n",
    "    \n",
    "    BACKBONE = 'resnet101'\n",
    "    \n",
    "    IMAGE_MIN_DIM = IMAGE_SIZE\n",
    "    IMAGE_MAX_DIM = IMAGE_SIZE    \n",
    "    IMAGE_RESIZE_MODE = 'none'\n",
    "    \n",
    "    \n",
    "config = FashionConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR/\"label_descriptions.json\") as f:\n",
    "    label_descriptions = json.load(f)\n",
    "\n",
    "label_names = [x['name'] for x in label_descriptions['categories']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the custom function that resizes an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_AREA)  \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crucial part is to create a dataset for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to use our model to predict test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glob_list = glob.glob(f'/kaggle/working/fashion*/mask_rcnn_fashion_{best_epoch:04d}.h5')\n",
    "#model_path = glob_list[0] if glob_list else ''\n",
    "model_path = '/home/ubuntu/efs/kaggle/imaterialist/maskrcnn/logs/fashion20190601T1940/mask_rcnn_fashion_0008.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell defines InferenceConfig and loads the best trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/github/Mask_RCNN/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Loading weights from  /home/ubuntu/efs/kaggle/imaterialist/maskrcnn/logs/fashion20190601T1940/mask_rcnn_fashion_0008.h5\n",
      "Re-starting from epoch 8\n"
     ]
    }
   ],
   "source": [
    "class InferenceConfig(FashionConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "model = modellib.MaskRCNN(mode='inference', \n",
    "                          config=inference_config,\n",
    "                          model_dir=ROOT_DIR)\n",
    "\n",
    "assert model_path != '', \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, load the submission data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>ClassId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003d41dd20f271d27219fe7ee6de727d.jpg</td>\n",
       "      <td>1 1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0046f98599f05fd7233973e430d6d04d.jpg</td>\n",
       "      <td>1 1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004e9e21cd1aca568a8ffc77a54638ce.jpg</td>\n",
       "      <td>1 1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005b37fce3c0f641d327d95dd832f51b.jpg</td>\n",
       "      <td>1 1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0094940c58c343b742f48ae26eb5e9fa.jpg</td>\n",
       "      <td>1 1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                ImageId EncodedPixels  ClassId\n",
       "0  003d41dd20f271d27219fe7ee6de727d.jpg           1 1       23\n",
       "1  0046f98599f05fd7233973e430d6d04d.jpg           1 1       23\n",
       "2  004e9e21cd1aca568a8ffc77a54638ce.jpg           1 1       23\n",
       "3  005b37fce3c0f641d327d95dd832f51b.jpg           1 1       23\n",
       "4  0094940c58c343b742f48ae26eb5e9fa.jpg           1 1       23"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = pd.read_csv(DATA_DIR/\"sample_submission.csv\")\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the main prediction steps, along with some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to run-length encoding\n",
    "def to_rle(bits):\n",
    "    rle = []\n",
    "    pos = 0\n",
    "    for bit, group in itertools.groupby(bits):\n",
    "        group_list = list(group)\n",
    "        if bit:\n",
    "            rle.extend([pos, sum(group_list)])\n",
    "        pos += len(group_list)\n",
    "    return rle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the submission system does not permit overlapped masks, we have to fix them\n",
    "def refine_masks(masks, rois):\n",
    "    areas = np.sum(masks.reshape(-1, masks.shape[-1]), axis=0)\n",
    "    mask_index = np.argsort(areas)\n",
    "    union_mask = np.zeros(masks.shape[:-1], dtype=bool)\n",
    "    for m in mask_index:\n",
    "        masks[:, :, m] = np.logical_and(masks[:, :, m], np.logical_not(union_mask))\n",
    "        union_mask = np.logical_or(masks[:, :, m], union_mask)\n",
    "    for m in range(masks.shape[-1]):\n",
    "        mask_pos = np.where(masks[:, :, m]==True)\n",
    "        if np.any(mask_pos):\n",
    "            y1, x1 = np.min(mask_pos, axis=1)\n",
    "            y2, x2 = np.max(mask_pos, axis=1)\n",
    "            rois[m, :] = [y1, x1, y2, x2]\n",
    "    return masks, rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3200/3200 [17:08<00:00,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min 14s, sys: 10min 23s, total: 31min 38s\n",
      "Wall time: 17min 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sub_list = []\n",
    "missing_count = 0\n",
    "for i, row in tqdm(sample_df.iterrows(), total=len(sample_df)):\n",
    "    image = resize_image(str(DATA_DIR/'test'/row['ImageId']))\n",
    "    result = model.detect([image])[0]\n",
    "    if result['masks'].size > 0:\n",
    "        masks, _ = refine_masks(result['masks'], result['rois'])\n",
    "        for m in range(masks.shape[-1]):\n",
    "            mask = masks[:, :, m].ravel(order='F')\n",
    "            rle = to_rle(mask)\n",
    "            label = result['class_ids'][m] - 1\n",
    "            sub_list.append([row['ImageId'], ' '.join(list(map(str, rle))), label])\n",
    "    else:\n",
    "        # The system does not allow missing ids, this is an easy way to fill them \n",
    "        sub_list.append([row['ImageId'], '1 0', 23])\n",
    "        missing_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The submission file is created, when all predictions are ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total image results:  3200\n",
      "Missing Images:  3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>ClassId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003d41dd20f271d27219fe7ee6de727d.jpg</td>\n",
       "      <td>170684 1 170694 12 171187 40 171693 61 172204 ...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>003d41dd20f271d27219fe7ee6de727d.jpg</td>\n",
       "      <td>72049 11 72558 16 73066 23 73571 31 74077 37 7...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003d41dd20f271d27219fe7ee6de727d.jpg</td>\n",
       "      <td>90496 45 90984 99 91489 110 91997 117 92507 12...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003d41dd20f271d27219fe7ee6de727d.jpg</td>\n",
       "      <td>105642 8 106153 11 106665 12 107176 14 107688 ...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003d41dd20f271d27219fe7ee6de727d.jpg</td>\n",
       "      <td>138743 2 138746 1 139254 3 139258 1 139765 4 1...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                ImageId  \\\n",
       "0  003d41dd20f271d27219fe7ee6de727d.jpg   \n",
       "1  003d41dd20f271d27219fe7ee6de727d.jpg   \n",
       "2  003d41dd20f271d27219fe7ee6de727d.jpg   \n",
       "3  003d41dd20f271d27219fe7ee6de727d.jpg   \n",
       "4  003d41dd20f271d27219fe7ee6de727d.jpg   \n",
       "\n",
       "                                       EncodedPixels  ClassId  \n",
       "0  170684 1 170694 12 171187 40 171693 61 172204 ...       31  \n",
       "1  72049 11 72558 16 73066 23 73571 31 74077 37 7...       31  \n",
       "2  90496 45 90984 99 91489 110 91997 117 92507 12...        8  \n",
       "3  105642 8 106153 11 106665 12 107176 14 107688 ...       29  \n",
       "4  138743 2 138746 1 139254 3 139258 1 139765 4 1...       21  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.DataFrame(sub_list, columns=sample_df.columns.values)\n",
    "print(\"Total image results: \", submission_df['ImageId'].nunique())\n",
    "print(\"Missing Images: \", missing_count)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it's pleasing to visualize the results! Sample images contain both fashion models and predictions from the Mask R-CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    image_id = sample_df.sample()['ImageId'].values[0]\n",
    "    image_path = str(DATA_DIR/'test'/image_id)\n",
    "    \n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    result = model.detect([resize_image(image_path)])\n",
    "    r = result[0]\n",
    "    \n",
    "    if r['masks'].size > 0:\n",
    "        masks = np.zeros((img.shape[0], img.shape[1], r['masks'].shape[-1]), dtype=np.uint8)\n",
    "        for m in range(r['masks'].shape[-1]):\n",
    "            masks[:, :, m] = cv2.resize(r['masks'][:, :, m].astype('uint8'), \n",
    "                                        (img.shape[1], img.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        y_scale = img.shape[0]/IMAGE_SIZE\n",
    "        x_scale = img.shape[1]/IMAGE_SIZE\n",
    "        rois = (r['rois'] * [y_scale, x_scale, y_scale, x_scale]).astype(int)\n",
    "        \n",
    "        masks, rois = refine_masks(masks, rois)\n",
    "    else:\n",
    "        masks, rois = r['masks'], r['rois']\n",
    "        \n",
    "    visualize.display_instances(img, rois, masks, r['class_ids'], \n",
    "                                ['bg']+label_names, r['scores'],\n",
    "                                title=image_id, figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions  submit imaterialist-fashion-2019-FGVC6 -f submission.csv -m \"fashion20190601T1940/mask_rcnn_fashion_0008.h5 mask loss 0.2906\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hope you guys like this kernel. If there are any bugs, please let me know.\n",
    "\n",
    "P.S. When clicking 'Submit to Competition' button, I always run into 404 erros, so I have to save a submission file and upload it to the submission page for submitting. The public LB score of this kernel is around **0.07**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
