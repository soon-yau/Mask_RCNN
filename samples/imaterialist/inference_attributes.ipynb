{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import imutils\n",
    "\n",
    "from ax import optimize\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchsummary\n",
    "\n",
    "from torchvision import models, transforms\n",
    "import torchvision\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, average_precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = Path('/home/ubuntu/efs/kaggle/imaterialist/test')\n",
    "DATA_DIR = Path('/home/ubuntu/efs/kaggle/imaterialist/')\n",
    "ROOT_DIR = Path('/home/ubuntu/efs/kaggle/imaterialist/maskrcnn/logs')\n",
    "\n",
    "# For demonstration purpose, the classification ignores attributes (only categories),\n",
    "# and the image size is set to 512, which is the same as the size of submission masks\n",
    "NUM_CATS = 46\n",
    "IMAGE_SIZE = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Resnet(\n",
       "    (base): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace)\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (6): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (7): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (8): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (9): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (10): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (11): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (12): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (13): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (14): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (15): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (16): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (17): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (18): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (19): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (20): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (21): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (22): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    )\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=512, out_features=92, bias=True)\n",
       "      (5): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Resnet, self).__init__()\n",
    "        base_model = models.resnet101(pretrained=True)\n",
    "        \n",
    "        self.base = nn.Sequential(*list(base_model.children())[:-1])\n",
    "        self.fc = nn.Sequential(\n",
    "                        nn.Linear(2048,1024),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(1024,512),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(512,92),\n",
    "                        nn.Sigmoid())\n",
    "\n",
    "    def forward(self, images, class_id):\n",
    "        features = self.base(images)\n",
    "        #class_id_repeat = class_id.repeat(12,1,1,1)\n",
    "        #class_id_repeat = class_id.view(-1,1, 1,1).repeat(1,12,1,1)\n",
    "        ##print(features.shape, class_id.shape, class_id_repeat.shape)\n",
    "        #x = torch.cat((features, class_id_repeat), dim=1)\n",
    "        #x = x.view((-1,2060))\n",
    "\n",
    "        y = self.fc(features.view((-1,2048)))\n",
    "        return y\n",
    "    \n",
    "model = Resnet().to(\"cuda\")\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "#model_path = \"/home/ubuntu/efs/kaggle/imaterialist/checkpoints/attribs/20190604-1603/model_step_11653.pth\"\n",
    "model_path = \"/home/ubuntu/efs/kaggle/imaterialist/checkpoints/attribs/20190605-1548/model_step_12864.pth\"\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttribsDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.n_attributes = 92\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        if row.EncodedPixels==\"1 0\":\n",
    "            return idx, np.zeros((3,512,512),dtype=np.float32), np.float32(100)\n",
    "        image_path = os.path.join(IMAGE_DIR, row.ImageId)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # mask out\n",
    "        original_h, original_w, _ = image.shape\n",
    "        h, w = 512, 512\n",
    "        mask = np.zeros((h*w), dtype=np.uint8)\n",
    "        \n",
    "        encodedPixels = list(map(int,row.EncodedPixels.split(' ')))\n",
    "        for startPos, runLen in zip(encodedPixels[0::2], encodedPixels[1::2]):\n",
    "            mask[startPos+1:startPos+1+runLen] = 1\n",
    "        mask = np.transpose(np.reshape(mask,(w,h)))\n",
    "        mask = cv2.resize(mask, (original_w, original_h))\n",
    "\n",
    "        # crop\n",
    "        bx,by,bw,bh = cv2.boundingRect(mask)\n",
    "        maskedImage = image* np.repeat(np.expand_dims(mask,-1), 3, axis=2)\n",
    "        cropped = maskedImage[by:by+bh, bx:bx+bw,:]\n",
    "\n",
    "        # resize largest dim to 512\n",
    "        resized_cropped = self.resize_apsect_ratio(cropped, 512)\n",
    "        class_id = row.ClassId\n",
    "        \n",
    "        resized_cropped = np.float32(resized_cropped.transpose((2, 0, 1)))/127.5 - 1\n",
    "        \n",
    "        return idx, resized_cropped, np.float32(class_id)\n",
    "    \n",
    "    def resize_apsect_ratio(self, img, dim=512):\n",
    "        img_h, img_w, _ = img.shape\n",
    "        if img_h>img_w:\n",
    "            resized = imutils.resize(img, height=dim)\n",
    "            total_pad = dim-resized.shape[1]\n",
    "            l_pad = total_pad//2\n",
    "            r_pad = total_pad -l_pad\n",
    "            resized = cv2.copyMakeBorder(resized, 0, 0, l_pad, r_pad, cv2.BORDER_CONSTANT, None, 0.0)\n",
    "        else:\n",
    "            resized = imutils.resize(img, width=dim)\n",
    "            total_pad = dim-resized.shape[0]\n",
    "            top_pad = total_pad//2\n",
    "            bottom_pad = total_pad -top_pad\n",
    "            resized = cv2.copyMakeBorder(resized,top_pad, bottom_pad,  0, 0, cv2.BORDER_CONSTANT, None, 0.0)\n",
    "        assert resized.shape[:2]==(dim, dim)\n",
    "        return resized\n",
    "    \n",
    "df = pd.read_csv(\"input.csv\")\n",
    "df[\"ClassId\"]=df[\"ClassId\"].astype(str)\n",
    "dataset = AttribsDataset(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 847/2155 [06:03<04:25,  4.93it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bb833a276c09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.42658067635687696\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_ids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     pred_labels = model(images.to(\"cuda\"),\n\u001b[1;32m      5\u001b[0m                         class_ids.to(\"cuda\"))\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                 \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_batch\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "threshold = 0.42658067635687696\n",
    "count = 0\n",
    "for idxs, images, class_ids in tqdm(dataloader):\n",
    "    pred_labels = model(images.to(\"cuda\"),\n",
    "                        class_ids.to(\"cuda\"))\n",
    "    for idx, pred, class_id in zip(idxs, pred_labels, class_ids):\n",
    "        if class_id<=12:\n",
    "            pred = pred.cpu().detach().numpy().astype(np.float16)\n",
    "            attrib_classes = np.where(pred>=threshold)[0]\n",
    "            if len(attrib_classes)>0:\n",
    "                attribs_idx = list(map(str,attrib_classes))\n",
    "                attribs = \"_\".join(attribs_idx)\n",
    "                labels = str(int(class_id))+'_'+attribs\n",
    "                i = idx.cpu().detach().numpy().astype(np.int)\n",
    "                df.at[int(i), \"ClassId\"] = labels\n",
    "                count+=1\n",
    "                if count>0:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n",
    "df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"%s attribs threshold %.4f\"%('/'.join(model_path.split('/')[-2:]), threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 16.0M/16.0M [00:07<00:00, 2.23MB/s]\n",
      "Successfully submitted to iMaterialist (Fashion) 2019 at FGVC6 "
     ]
    }
   ],
   "source": [
    "!kaggle competitions  submit imaterialist-fashion-2019-FGVC6 -f submission.csv -m message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attributes.ipynb\t    input.csv\t\t      __pycache__\r\n",
      "attributes.py\t\t    inspect_attributes.ipynb  runs\r\n",
      "coco.py\t\t\t    inspect_data.ipynb\t      submission.csv\r\n",
      "inference_attributes.ipynb  inspect_model.ipynb\r\n",
      "inference.ipynb\t\t    inspect_weights.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>ClassId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003d41dd20f271d27219fe7ee6de727d.jpg</td>\n",
       "      <td>87453 6 87957 20 88464 29 88972 36 89479 45 89...</td>\n",
       "      <td>8_20_42_53_61_85_91_20_42_60_91_20_41_60_62_0_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>003d41dd20f271d27219fe7ee6de727d.jpg</td>\n",
       "      <td>171208 9 171254 8 171705 8 171717 17 171763 19...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003d41dd20f271d27219fe7ee6de727d.jpg</td>\n",
       "      <td>72562 12 73069 20 73575 26 74079 34 74578 47 7...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003d41dd20f271d27219fe7ee6de727d.jpg</td>\n",
       "      <td>137721 5 138231 1 138233 6 138741 10 139242 7 ...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003d41dd20f271d27219fe7ee6de727d.jpg</td>\n",
       "      <td>104104 1 104615 3 105127 3 105638 5 106150 5 1...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>003d41dd20f271d27219fe7ee6de727d.jpg</td>\n",
       "      <td>107180 2 107693 2 108206 2 108719 2 109231 2 1...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0046f98599f05fd7233973e430d6d04d.jpg</td>\n",
       "      <td>129665 2 129669 1 130174 13 130188 2 130686 9 ...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0046f98599f05fd7233973e430d6d04d.jpg</td>\n",
       "      <td>84891 4 85392 26 85901 31 86411 34 86921 38 87...</td>\n",
       "      <td>10_20_42_53_61_85_91_20_42_60_91_20_41_60_62_0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0046f98599f05fd7233973e430d6d04d.jpg</td>\n",
       "      <td>211820 6 217485 2 217995 6 218506 9 219018 10 ...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>004e9e21cd1aca568a8ffc77a54638ce.jpg</td>\n",
       "      <td>66897 45 67395 62 67901 70 68410 74 68919 78 6...</td>\n",
       "      <td>8_0_20_41_14_20_34_61_19_60_61_91_20_61_20_41_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>004e9e21cd1aca568a8ffc77a54638ce.jpg</td>\n",
       "      <td>151706 12 152213 21 152722 27 153231 32 153740...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>004e9e21cd1aca568a8ffc77a54638ce.jpg</td>\n",
       "      <td>68782 18 69286 35 69794 42 70303 48 70812 52 7...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>004e9e21cd1aca568a8ffc77a54638ce.jpg</td>\n",
       "      <td>123338 5 123848 9 124359 14 124390 7 124871 39...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>004e9e21cd1aca568a8ffc77a54638ce.jpg</td>\n",
       "      <td>131194 2 131703 7 132212 11 132724 11 133235 1...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>004e9e21cd1aca568a8ffc77a54638ce.jpg</td>\n",
       "      <td>100292 11 100803 14 101314 15 101827 14 102341...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>004e9e21cd1aca568a8ffc77a54638ce.jpg</td>\n",
       "      <td>81127 1 81639 1 82150 2 82661 3 83173 3 83685 ...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>004e9e21cd1aca568a8ffc77a54638ce.jpg</td>\n",
       "      <td>72338 2 72848 2 73358 1 75896 4 76406 1 76506 ...</td>\n",
       "      <td>0_0_20_41_61_88_61_61_20_41_60_88_0_19_40_61_6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>004e9e21cd1aca568a8ffc77a54638ce.jpg</td>\n",
       "      <td>114772 2 114783 3 115282 5 115292 7 115793 6 1...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>004e9e21cd1aca568a8ffc77a54638ce.jpg</td>\n",
       "      <td>80483 1 80994 2 81506 2 82017 2 82529 2 83040 ...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>005b37fce3c0f641d327d95dd832f51b.jpg</td>\n",
       "      <td>76027 9 76524 29 77031 46 77527 72 78032 91 78...</td>\n",
       "      <td>1_0_20_41_61_88_61_61_20_41_60_88_0_19_40_61_6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>005b37fce3c0f641d327d95dd832f51b.jpg</td>\n",
       "      <td>83333 11 83845 30 84357 34 84869 36 85382 37 8...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>005b37fce3c0f641d327d95dd832f51b.jpg</td>\n",
       "      <td>113488 5 113999 7 114511 7 115024 7 115536 8 1...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>005b37fce3c0f641d327d95dd832f51b.jpg</td>\n",
       "      <td>83837 8 84345 12 84856 13 85368 14 85880 15 85...</td>\n",
       "      <td>6_0_20_41_61_88_61_61_20_41_60_88_0_19_40_61_6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>005b37fce3c0f641d327d95dd832f51b.jpg</td>\n",
       "      <td>81502 4 82010 9 82520 10 83028 12 83537 12 840...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>005b37fce3c0f641d327d95dd832f51b.jpg</td>\n",
       "      <td>112817 18 113320 47 113818 7 113827 53 114327 ...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0094940c58c343b742f48ae26eb5e9fa.jpg</td>\n",
       "      <td>8537 4 9048 8 9559 11 10070 13 10581 15 11092 ...</td>\n",
       "      <td>10_0_20_60_88_9_14_20_22_24_67_20_42_61_85_20_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0094940c58c343b742f48ae26eb5e9fa.jpg</td>\n",
       "      <td>122311 8 122822 11 122840 21 123335 1 123340 6...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0094940c58c343b742f48ae26eb5e9fa.jpg</td>\n",
       "      <td>114313 2 114814 15 114864 4 115321 3 115325 19...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0094940c58c343b742f48ae26eb5e9fa.jpg</td>\n",
       "      <td>88963 1 89475 2 89986 3 90498 4 91010 4 91522 ...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0094940c58c343b742f48ae26eb5e9fa.jpg</td>\n",
       "      <td>138226 5 138725 18 139237 19 139749 19 140261 ...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>00a8764cff12b2e849c850f4be5608bc.jpg</td>\n",
       "      <td>108835 5 109342 10 109851 13 110361 16 110871 ...</td>\n",
       "      <td>1_0_20_40_61_87_20_40_61_20_40_61_42_61_85_61_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>00a8764cff12b2e849c850f4be5608bc.jpg</td>\n",
       "      <td>88488 11 88992 21 89502 24 90013 25 90523 27 9...</td>\n",
       "      <td>8_0_20_40_61_87_20_40_61_20_40_61_42_61_85_61_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>00a8764cff12b2e849c850f4be5608bc.jpg</td>\n",
       "      <td>30031 49 30535 60 31043 65 31551 69 32059 74 3...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>00a8764cff12b2e849c850f4be5608bc.jpg</td>\n",
       "      <td>36739 1 37251 1 37763 1 38275 1 38786 2 39298 ...</td>\n",
       "      <td>4_20_41_60_61_91_20_41_61_61_20_41_61_61_20_41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>00a8764cff12b2e849c850f4be5608bc.jpg</td>\n",
       "      <td>115133 2 115645 4 116156 9 116668 13 117180 15...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>00a8764cff12b2e849c850f4be5608bc.jpg</td>\n",
       "      <td>160508 5 161018 14 161527 19 162037 22 162547 ...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>00a8764cff12b2e849c850f4be5608bc.jpg</td>\n",
       "      <td>53244 3 53754 5 54266 6 54777 7 55288 8 55799 ...</td>\n",
       "      <td>6_20_41_60_61_91_20_41_61_61_20_41_61_61_20_41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>00a8764cff12b2e849c850f4be5608bc.jpg</td>\n",
       "      <td>78589 4 79101 5 79612 7 80124 8 80636 9 81149 ...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>00a8764cff12b2e849c850f4be5608bc.jpg</td>\n",
       "      <td>85675 5 86186 13 86698 14 87210 14 87722 15 88...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>00d5da56c02d426c4e4bf802b1888471.jpg</td>\n",
       "      <td>172138 1 172648 5 173159 9 173672 9 174186 9 1...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>00d5da56c02d426c4e4bf802b1888471.jpg</td>\n",
       "      <td>136627 1 137139 2 137651 2 138163 2 138674 3 1...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>00d5da56c02d426c4e4bf802b1888471.jpg</td>\n",
       "      <td>112041 4 112551 7 113063 8 113575 9 114087 10 ...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>00d5da56c02d426c4e4bf802b1888471.jpg</td>\n",
       "      <td>124662 1 125171 10 125680 14 126191 15 126702 ...</td>\n",
       "      <td>10_0_20_61_87_0_20_61_3_20_34_53_61_87_88_0_40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>00d6e5891b7507fccbd49f2c2756b114.jpg</td>\n",
       "      <td>116886 1 117398 2 117910 2 118422 2 118933 3 1...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>00d6e5891b7507fccbd49f2c2756b114.jpg</td>\n",
       "      <td>99108 28 99605 53 100112 62 100619 71 101123 8...</td>\n",
       "      <td>10_0_20_61_87_0_20_61_3_20_34_53_61_87_88_0_40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>00d6e5891b7507fccbd49f2c2756b114.jpg</td>\n",
       "      <td>129949 1 130461 2 130973 2 131485 1 131997 1 1...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>00e45dd233e31906f538ba17dd45bf29.jpg</td>\n",
       "      <td>19371 70 19879 81 20388 87 20898 90 21408 93 2...</td>\n",
       "      <td>10_0_20_61_87_0_20_61_3_20_34_53_61_87_88_0_40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>00e45dd233e31906f538ba17dd45bf29.jpg</td>\n",
       "      <td>174323 4 174833 6 175344 7 175854 9 176358 17 ...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>00e45dd233e31906f538ba17dd45bf29.jpg</td>\n",
       "      <td>100526 4 101034 13 101545 17 102056 21 102567 ...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>00e45dd233e31906f538ba17dd45bf29.jpg</td>\n",
       "      <td>82670 4 82676 4 83181 14 83697 11 84209 12 847...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>00e45dd233e31906f538ba17dd45bf29.jpg</td>\n",
       "      <td>72989 6 73497 13 74006 19 74516 24 75026 28 75...</td>\n",
       "      <td>1_0_42_61_91_20_61_20_40_61_88_61_5_14_20_24_6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>00f1db534538841931f15f2bb5cec76c.jpg</td>\n",
       "      <td>89184 2 89695 3 90209 2 90721 3 91234 3 91747 ...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>00f1db534538841931f15f2bb5cec76c.jpg</td>\n",
       "      <td>66839 11 67350 14 67861 16 68373 17 68884 20 6...</td>\n",
       "      <td>10_0_42_61_91_20_61_20_40_61_88_61_5_14_20_24_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>00f1db534538841931f15f2bb5cec76c.jpg</td>\n",
       "      <td>96710 6 97221 9 97733 10 98244 6 98251 4 98757...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>00f1db534538841931f15f2bb5cec76c.jpg</td>\n",
       "      <td>91701 2 92212 6 92724 8 93236 9 93747 10 94259...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>00f1db534538841931f15f2bb5cec76c.jpg</td>\n",
       "      <td>100746 2 101772 3 102284 5 102796 7 103310 13 ...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>00f1db534538841931f15f2bb5cec76c.jpg</td>\n",
       "      <td>115629 5 116140 1 116143 4 116647 6 116656 4 1...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>00faa1032cc0809974a8d2dd7b018497.jpg</td>\n",
       "      <td>128475 2 128986 5 129499 6 129981 7 130011 6 1...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>00faa1032cc0809974a8d2dd7b018497.jpg</td>\n",
       "      <td>114629 9 115131 21 115640 26 116143 36 116651 ...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>00faa1032cc0809974a8d2dd7b018497.jpg</td>\n",
       "      <td>102631 41 103137 53 103647 58 104157 62 104666...</td>\n",
       "      <td>10_61_61_0_20_41_53_61_14_20_61_85_20_61_14_20...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ImageId  \\\n",
       "0   003d41dd20f271d27219fe7ee6de727d.jpg   \n",
       "1   003d41dd20f271d27219fe7ee6de727d.jpg   \n",
       "2   003d41dd20f271d27219fe7ee6de727d.jpg   \n",
       "3   003d41dd20f271d27219fe7ee6de727d.jpg   \n",
       "4   003d41dd20f271d27219fe7ee6de727d.jpg   \n",
       "5   003d41dd20f271d27219fe7ee6de727d.jpg   \n",
       "6   0046f98599f05fd7233973e430d6d04d.jpg   \n",
       "7   0046f98599f05fd7233973e430d6d04d.jpg   \n",
       "8   0046f98599f05fd7233973e430d6d04d.jpg   \n",
       "9   004e9e21cd1aca568a8ffc77a54638ce.jpg   \n",
       "10  004e9e21cd1aca568a8ffc77a54638ce.jpg   \n",
       "11  004e9e21cd1aca568a8ffc77a54638ce.jpg   \n",
       "12  004e9e21cd1aca568a8ffc77a54638ce.jpg   \n",
       "13  004e9e21cd1aca568a8ffc77a54638ce.jpg   \n",
       "14  004e9e21cd1aca568a8ffc77a54638ce.jpg   \n",
       "15  004e9e21cd1aca568a8ffc77a54638ce.jpg   \n",
       "16  004e9e21cd1aca568a8ffc77a54638ce.jpg   \n",
       "17  004e9e21cd1aca568a8ffc77a54638ce.jpg   \n",
       "18  004e9e21cd1aca568a8ffc77a54638ce.jpg   \n",
       "19  005b37fce3c0f641d327d95dd832f51b.jpg   \n",
       "20  005b37fce3c0f641d327d95dd832f51b.jpg   \n",
       "21  005b37fce3c0f641d327d95dd832f51b.jpg   \n",
       "22  005b37fce3c0f641d327d95dd832f51b.jpg   \n",
       "23  005b37fce3c0f641d327d95dd832f51b.jpg   \n",
       "24  005b37fce3c0f641d327d95dd832f51b.jpg   \n",
       "25  0094940c58c343b742f48ae26eb5e9fa.jpg   \n",
       "26  0094940c58c343b742f48ae26eb5e9fa.jpg   \n",
       "27  0094940c58c343b742f48ae26eb5e9fa.jpg   \n",
       "28  0094940c58c343b742f48ae26eb5e9fa.jpg   \n",
       "29  0094940c58c343b742f48ae26eb5e9fa.jpg   \n",
       "..                                   ...   \n",
       "70  00a8764cff12b2e849c850f4be5608bc.jpg   \n",
       "71  00a8764cff12b2e849c850f4be5608bc.jpg   \n",
       "72  00a8764cff12b2e849c850f4be5608bc.jpg   \n",
       "73  00a8764cff12b2e849c850f4be5608bc.jpg   \n",
       "74  00a8764cff12b2e849c850f4be5608bc.jpg   \n",
       "75  00a8764cff12b2e849c850f4be5608bc.jpg   \n",
       "76  00a8764cff12b2e849c850f4be5608bc.jpg   \n",
       "77  00a8764cff12b2e849c850f4be5608bc.jpg   \n",
       "78  00a8764cff12b2e849c850f4be5608bc.jpg   \n",
       "79  00d5da56c02d426c4e4bf802b1888471.jpg   \n",
       "80  00d5da56c02d426c4e4bf802b1888471.jpg   \n",
       "81  00d5da56c02d426c4e4bf802b1888471.jpg   \n",
       "82  00d5da56c02d426c4e4bf802b1888471.jpg   \n",
       "83  00d6e5891b7507fccbd49f2c2756b114.jpg   \n",
       "84  00d6e5891b7507fccbd49f2c2756b114.jpg   \n",
       "85  00d6e5891b7507fccbd49f2c2756b114.jpg   \n",
       "86  00e45dd233e31906f538ba17dd45bf29.jpg   \n",
       "87  00e45dd233e31906f538ba17dd45bf29.jpg   \n",
       "88  00e45dd233e31906f538ba17dd45bf29.jpg   \n",
       "89  00e45dd233e31906f538ba17dd45bf29.jpg   \n",
       "90  00e45dd233e31906f538ba17dd45bf29.jpg   \n",
       "91  00f1db534538841931f15f2bb5cec76c.jpg   \n",
       "92  00f1db534538841931f15f2bb5cec76c.jpg   \n",
       "93  00f1db534538841931f15f2bb5cec76c.jpg   \n",
       "94  00f1db534538841931f15f2bb5cec76c.jpg   \n",
       "95  00f1db534538841931f15f2bb5cec76c.jpg   \n",
       "96  00f1db534538841931f15f2bb5cec76c.jpg   \n",
       "97  00faa1032cc0809974a8d2dd7b018497.jpg   \n",
       "98  00faa1032cc0809974a8d2dd7b018497.jpg   \n",
       "99  00faa1032cc0809974a8d2dd7b018497.jpg   \n",
       "\n",
       "                                        EncodedPixels  \\\n",
       "0   87453 6 87957 20 88464 29 88972 36 89479 45 89...   \n",
       "1   171208 9 171254 8 171705 8 171717 17 171763 19...   \n",
       "2   72562 12 73069 20 73575 26 74079 34 74578 47 7...   \n",
       "3   137721 5 138231 1 138233 6 138741 10 139242 7 ...   \n",
       "4   104104 1 104615 3 105127 3 105638 5 106150 5 1...   \n",
       "5   107180 2 107693 2 108206 2 108719 2 109231 2 1...   \n",
       "6   129665 2 129669 1 130174 13 130188 2 130686 9 ...   \n",
       "7   84891 4 85392 26 85901 31 86411 34 86921 38 87...   \n",
       "8   211820 6 217485 2 217995 6 218506 9 219018 10 ...   \n",
       "9   66897 45 67395 62 67901 70 68410 74 68919 78 6...   \n",
       "10  151706 12 152213 21 152722 27 153231 32 153740...   \n",
       "11  68782 18 69286 35 69794 42 70303 48 70812 52 7...   \n",
       "12  123338 5 123848 9 124359 14 124390 7 124871 39...   \n",
       "13  131194 2 131703 7 132212 11 132724 11 133235 1...   \n",
       "14  100292 11 100803 14 101314 15 101827 14 102341...   \n",
       "15  81127 1 81639 1 82150 2 82661 3 83173 3 83685 ...   \n",
       "16  72338 2 72848 2 73358 1 75896 4 76406 1 76506 ...   \n",
       "17  114772 2 114783 3 115282 5 115292 7 115793 6 1...   \n",
       "18  80483 1 80994 2 81506 2 82017 2 82529 2 83040 ...   \n",
       "19  76027 9 76524 29 77031 46 77527 72 78032 91 78...   \n",
       "20  83333 11 83845 30 84357 34 84869 36 85382 37 8...   \n",
       "21  113488 5 113999 7 114511 7 115024 7 115536 8 1...   \n",
       "22  83837 8 84345 12 84856 13 85368 14 85880 15 85...   \n",
       "23  81502 4 82010 9 82520 10 83028 12 83537 12 840...   \n",
       "24  112817 18 113320 47 113818 7 113827 53 114327 ...   \n",
       "25  8537 4 9048 8 9559 11 10070 13 10581 15 11092 ...   \n",
       "26  122311 8 122822 11 122840 21 123335 1 123340 6...   \n",
       "27  114313 2 114814 15 114864 4 115321 3 115325 19...   \n",
       "28  88963 1 89475 2 89986 3 90498 4 91010 4 91522 ...   \n",
       "29  138226 5 138725 18 139237 19 139749 19 140261 ...   \n",
       "..                                                ...   \n",
       "70  108835 5 109342 10 109851 13 110361 16 110871 ...   \n",
       "71  88488 11 88992 21 89502 24 90013 25 90523 27 9...   \n",
       "72  30031 49 30535 60 31043 65 31551 69 32059 74 3...   \n",
       "73  36739 1 37251 1 37763 1 38275 1 38786 2 39298 ...   \n",
       "74  115133 2 115645 4 116156 9 116668 13 117180 15...   \n",
       "75  160508 5 161018 14 161527 19 162037 22 162547 ...   \n",
       "76  53244 3 53754 5 54266 6 54777 7 55288 8 55799 ...   \n",
       "77  78589 4 79101 5 79612 7 80124 8 80636 9 81149 ...   \n",
       "78  85675 5 86186 13 86698 14 87210 14 87722 15 88...   \n",
       "79  172138 1 172648 5 173159 9 173672 9 174186 9 1...   \n",
       "80  136627 1 137139 2 137651 2 138163 2 138674 3 1...   \n",
       "81  112041 4 112551 7 113063 8 113575 9 114087 10 ...   \n",
       "82  124662 1 125171 10 125680 14 126191 15 126702 ...   \n",
       "83  116886 1 117398 2 117910 2 118422 2 118933 3 1...   \n",
       "84  99108 28 99605 53 100112 62 100619 71 101123 8...   \n",
       "85  129949 1 130461 2 130973 2 131485 1 131997 1 1...   \n",
       "86  19371 70 19879 81 20388 87 20898 90 21408 93 2...   \n",
       "87  174323 4 174833 6 175344 7 175854 9 176358 17 ...   \n",
       "88  100526 4 101034 13 101545 17 102056 21 102567 ...   \n",
       "89  82670 4 82676 4 83181 14 83697 11 84209 12 847...   \n",
       "90  72989 6 73497 13 74006 19 74516 24 75026 28 75...   \n",
       "91  89184 2 89695 3 90209 2 90721 3 91234 3 91747 ...   \n",
       "92  66839 11 67350 14 67861 16 68373 17 68884 20 6...   \n",
       "93  96710 6 97221 9 97733 10 98244 6 98251 4 98757...   \n",
       "94  91701 2 92212 6 92724 8 93236 9 93747 10 94259...   \n",
       "95  100746 2 101772 3 102284 5 102796 7 103310 13 ...   \n",
       "96  115629 5 116140 1 116143 4 116647 6 116656 4 1...   \n",
       "97  128475 2 128986 5 129499 6 129981 7 130011 6 1...   \n",
       "98  114629 9 115131 21 115640 26 116143 36 116651 ...   \n",
       "99  102631 41 103137 53 103647 58 104157 62 104666...   \n",
       "\n",
       "                                              ClassId  \n",
       "0   8_20_42_53_61_85_91_20_42_60_91_20_41_60_62_0_...  \n",
       "1                                                  31  \n",
       "2                                                  31  \n",
       "3                                                  21  \n",
       "4                                                  28  \n",
       "5                                                  33  \n",
       "6                                                  33  \n",
       "7   10_20_42_53_61_85_91_20_42_60_91_20_41_60_62_0...  \n",
       "8                                                  24  \n",
       "9   8_0_20_41_14_20_34_61_19_60_61_91_20_61_20_41_...  \n",
       "10                                                 31  \n",
       "11                                                 31  \n",
       "12                                                 23  \n",
       "13                                                 36  \n",
       "14                                                 23  \n",
       "15                                                 18  \n",
       "16  0_0_20_41_61_88_61_61_20_41_60_88_0_19_40_61_6...  \n",
       "17                                                 28  \n",
       "18                                                 30  \n",
       "19  1_0_20_41_61_88_61_61_20_41_60_88_0_19_40_61_6...  \n",
       "20                                                 32  \n",
       "21                                                 18  \n",
       "22  6_0_20_41_61_88_61_61_20_41_60_88_0_19_40_61_6...  \n",
       "23                                                 14  \n",
       "24                                                 31  \n",
       "25  10_0_20_60_88_9_14_20_22_24_67_20_42_61_85_20_...  \n",
       "26                                                 23  \n",
       "27                                                 33  \n",
       "28                                                 41  \n",
       "29                                                 23  \n",
       "..                                                ...  \n",
       "70  1_0_20_40_61_87_20_40_61_20_40_61_42_61_85_61_...  \n",
       "71  8_0_20_40_61_87_20_40_61_20_40_61_42_61_85_61_...  \n",
       "72                                                 31  \n",
       "73  4_20_41_60_61_91_20_41_61_61_20_41_61_61_20_41...  \n",
       "74                                                 21  \n",
       "75                                                 31  \n",
       "76  6_20_41_60_61_91_20_41_61_61_20_41_61_61_20_41...  \n",
       "77                                                 32  \n",
       "78                                                 29  \n",
       "79                                                 33  \n",
       "80                                                 23  \n",
       "81                                                 23  \n",
       "82  10_0_20_61_87_0_20_61_3_20_34_53_61_87_88_0_40...  \n",
       "83                                                 33  \n",
       "84  10_0_20_61_87_0_20_61_3_20_34_53_61_87_88_0_40...  \n",
       "85                                                 23  \n",
       "86  10_0_20_61_87_0_20_61_3_20_34_53_61_87_88_0_40...  \n",
       "87                                                 31  \n",
       "88                                                 28  \n",
       "89                                                 32  \n",
       "90  1_0_42_61_91_20_61_20_40_61_88_61_5_14_20_24_6...  \n",
       "91                                                 33  \n",
       "92  10_0_42_61_91_20_61_20_40_61_88_61_5_14_20_24_...  \n",
       "93                                                 23  \n",
       "94                                                 13  \n",
       "95                                                 23  \n",
       "96                                                 23  \n",
       "97                                                 23  \n",
       "98                                                 23  \n",
       "99  10_61_61_0_20_41_53_61_14_20_61_85_20_61_14_20...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
