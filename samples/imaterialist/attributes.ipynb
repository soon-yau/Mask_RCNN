{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import imutils\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchsummary\n",
    "\n",
    "from torchvision import models, transforms\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = Path('/home/ubuntu/efs/kaggle/imaterialist/train')\n",
    "DATA_DIR = Path('/home/ubuntu/efs/kaggle/imaterialist/')\n",
    "ROOT_DIR = Path('/home/ubuntu/efs/kaggle/imaterialist/maskrcnn/logs')\n",
    "\n",
    "# For demonstration purpose, the classification ignores attributes (only categories),\n",
    "# and the image size is set to 512, which is the same as the size of submission masks\n",
    "NUM_CATS = 46\n",
    "IMAGE_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith open(DATA_DIR/\"label_descriptions.json\") as f:\\n    label_descriptions = json.load(f)\\n\\nlabel_names = [x[\\'name\\'] for x in label_descriptions[\\'categories\\']]\\nattributes_list = [i[\\'name\\'] for i in label_descriptions[\\'attributes\\']]\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "with open(DATA_DIR/\"label_descriptions.json\") as f:\n",
    "    label_descriptions = json.load(f)\n",
    "\n",
    "label_names = [x['name'] for x in label_descriptions['categories']]\n",
    "attributes_list = [i['name'] for i in label_descriptions['attributes']]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttribsDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.n_attributes = 92\n",
    "        '''\n",
    "        # create dataset\n",
    "        segment_df = pd.read_csv(DATA_DIR/\"train.csv\")\n",
    "        idx_with_attribs = segment_df['ClassId'].str.contains('_')\n",
    "        idx_without_attribs = ~idx_with_attribs\n",
    "\n",
    "        segment_with_attribs = segment_df[idx_with_attribs]\n",
    "        n_without_attribs = len(segment_with_attribs)//2\n",
    "        segment_without_attribs = pd.DataFrame.sample(segment_df[idx_without_attribs], n=n_without_attribs) \n",
    "        \n",
    "        self.df = pd.concat([segment_with_attribs, segment_without_attribs])\n",
    "        '''\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open(os.path.join(IMAGE_DIR, row.ImageId))\n",
    "\n",
    "        # mask out\n",
    "        h, w = row.Height, row.Width\n",
    "        mask = np.zeros((h*w), dtype=np.uint8)\n",
    "        encodedPixels = list(map(int,row.EncodedPixels.split(' ')))\n",
    "        for startPos, runLen in zip(encodedPixels[0::2], encodedPixels[1::2]):\n",
    "            mask[startPos+1:startPos+1+runLen] = 1\n",
    "        mask = np.transpose(np.reshape(mask,(w,h)))        \n",
    "        #plt.imshow(mask)\n",
    "\n",
    "        # crop\n",
    "        bx,by,bw,bh = cv2.boundingRect(mask)\n",
    "        maskedImage = image* np.repeat(np.expand_dims(mask,-1), 3, axis=2)\n",
    "        cropped = maskedImage[by:by+bh, bx:bx+bw,:]\n",
    "\n",
    "        # resize largest dim to 512\n",
    "        resized_cropped = self.resize_apsect_ratio(cropped, 512)\n",
    "        #plt.imshow(resized_cropped)\n",
    "        #plt.show()\n",
    "        class_id = int(row.ClassId.split('_')[0])\n",
    "        #print(\"Class ID\", class_id, label_names[class_id])\n",
    "\n",
    "        attributes = row.ClassId.split('_')[1:]\n",
    "        #for attrib in attributes:\n",
    "        #    print(attrib, attributes_list[int(attrib)])\n",
    "\n",
    "        labels = np.zeros((self.n_attributes), np.float32)\n",
    "        labels[np.array(list(map(int,attributes)))] = 1\n",
    "        \n",
    "        resized_cropped = np.float32(resized_cropped.transpose((2, 0, 1)))/255. -1\n",
    "        \n",
    "        return resized_cropped, np.float32(class_id), labels\n",
    "    \n",
    "    def resize_apsect_ratio(self, img, dim=512):\n",
    "        img_h, img_w, _ = img.shape\n",
    "        if img_h>img_w:\n",
    "            resized = imutils.resize(img, height=dim)\n",
    "            total_pad = dim-resized.shape[1]\n",
    "            l_pad = total_pad//2\n",
    "            r_pad = total_pad -l_pad\n",
    "            resized = cv2.copyMakeBorder(resized, 0, 0, l_pad, r_pad, cv2.BORDER_CONSTANT, None, 0.0)\n",
    "        else:\n",
    "            resized = imutils.resize(img, width=dim)\n",
    "            total_pad = dim-resized.shape[0]\n",
    "            top_pad = total_pad//2\n",
    "            bottom_pad = total_pad -top_pad\n",
    "            resized = cv2.copyMakeBorder(resized,top_pad, bottom_pad,  0, 0, cv2.BORDER_CONSTANT, None, 0.0)\n",
    "        assert resized.shape[:2]==(dim, dim)\n",
    "        return resized        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_df = pd.read_csv(DATA_DIR/\"train.csv\")\n",
    "idx_with_attribs = segment_df['ClassId'].str.contains('_')\n",
    "idx_without_attribs = ~idx_with_attribs\n",
    "\n",
    "segment_with_attribs = segment_df[idx_with_attribs]\n",
    "n_with_attribs = len(segment_with_attribs)\n",
    "# make total to be multiples of 32\n",
    "n_without_attribs = int(n_with_attribs//32*32*1.5-n_with_attribs)\n",
    "segment_without_attribs = pd.DataFrame.sample(segment_df[idx_without_attribs], n=n_without_attribs) \n",
    "\n",
    "df = pd.concat([segment_with_attribs, segment_without_attribs])\n",
    "assert(len(df)%32==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rkf = RepeatedKFold(n_splits=6, n_repeats=10, random_state=8888)\n",
    "df_folder = rkf.split(df)\n",
    "\n",
    "def gen_dataset():\n",
    "    train_index, val_index = next(df_folder)\n",
    "    train_df = df.iloc[train_index]\n",
    "    valid_df = df.iloc[val_index]\n",
    "    \n",
    "    train_dataset = AttribsDataset(train_df)\n",
    "\n",
    "    valid_dataset = AttribsDataset(valid_df)\n",
    "    \n",
    "    return train_dataset, valid_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d32e76923afe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "class Resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Resnet, self).__init__()\n",
    "        base_model = models.resnet101(pretrained=True)\n",
    "        \n",
    "        self.base = nn.Sequential(*list(base_model.children())[:-1])\n",
    "        self.fc = nn.Sequential(\n",
    "                        nn.Linear(2060,500),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(500,92),\n",
    "                        nn.Sigmoid())\n",
    "                \n",
    "    def forward(self, images, class_id):\n",
    "        features = self.base(images)\n",
    "        #class_id_repeat = class_id.repeat(12,1,1,1)\n",
    "        class_id_repeat = class_id.view(-1,1, 1,1).repeat(1,12,1,1)\n",
    "        #print(features.shape, class_id.shape, class_id_repeat.shape)\n",
    "        x = torch.cat((features, class_id_repeat), dim=1)\n",
    "        x = x.view((-1,2060))\n",
    "\n",
    "        y = self.fc(x)\n",
    "        return y\n",
    "    \n",
    "model = Resnet().to(\"cuda\")\n",
    "model = nn.DataParallel(model)\n",
    "#output = model(images.to(\"cuda\"), class_id.to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    log = SummaryWriter()\n",
    "    logdir = \"/home/ubuntu/efs/kaggle/imaterialist/checkpoints/attribs/%s\"%\\\n",
    "                    datetime.now().strftime('%Y%m%d-%H%M')\n",
    "    \n",
    "    if os.path.isdir(logdir) != True:        \n",
    "        os.makedirs(logdir)\n",
    "        print(\"Create directory \", logdir)\n",
    "\n",
    "    #best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 10000.0\n",
    "    step = 0\n",
    "    stepInEpoch = 0\n",
    "    since = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        if epoch%10 == 0:\n",
    "            print(\"Getting new fold of dataset\")\n",
    "            train_dataset, val_dataset = gen_dataset()\n",
    "            dataLoaders = {'train':DataLoader(train_dataset, batch_size=batch_size, num_workers=8),\n",
    "                           'val':DataLoader(val_dataset, batch_size=batch_size, num_workers=8)}\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train','val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            image_count = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for images, class_ids, labels in dataLoaders[phase]: \n",
    "                images = images.to(\"cuda:0\")\n",
    "                class_ids = class_ids.to(\"cuda:0\")\n",
    "                labels = labels.to(\"cuda:0\")\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(images, class_ids)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                image_count += images.size(0)\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                if phase =='train' and step%10 == 0:\n",
    "                    timeElapsed = time.time() - since\n",
    "                    since = time.time()\n",
    "                    meanLoss = running_loss/image_count\n",
    "                    print('[%d] training loss=%.4f Time in %.0f m %.0f s'%\\\n",
    "                          (step, loss.item(), timeElapsed//60, timeElapsed%60))                    \n",
    "                        \n",
    "                    # log\n",
    "                    log.add_scalar(\"train_loss\", loss.item(), step)\n",
    "                    log.add_scalar(\"learning_rate\", scheduler.get_lr()[0], step)\n",
    "\n",
    "                step+=1\n",
    "                \n",
    "            #epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_loss = running_loss / image_count\n",
    "            # deep copy the model\n",
    "            if phase =='val':\n",
    "                print('[Epoch %d] Valid loss=%.4f'%(epoch, epoch_loss))\n",
    "                # log\n",
    "                log.add_scalar(\"valid_loss\", epoch_loss, step)\n",
    "                    \n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    #best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    \n",
    "                    modelName = '%s/model_step_%d.pth' % (logdir, step)\n",
    "                    torch.save(model.state_dict(), modelName)\n",
    "                    print(\"Save model \",modelName)\n",
    "        #print('{} Loss: {:.4f}'.format(\n",
    "            #    phase, epoch_loss))\n",
    "\n",
    "\n",
    "        #print()\n",
    "\n",
    "\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    #model.load_state_dict(best_model_wts)\n",
    "    #return model\n",
    "\n",
    "\n",
    "# Optimizer\n",
    "learningRate = 1e-3\n",
    "\n",
    "nEpoch = 100\n",
    "lrDecayStep = 3\n",
    "lrDecayRate = 0.95\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = learningRate)\n",
    "expDecayOptimizer = optim.lr_scheduler.StepLR(optimizer, step_size=lrDecayStep, gamma=lrDecayRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create directory  /home/ubuntu/efs/kaggle/imaterialist/checkpoints/attribs/20190604-1324\n",
      "Getting new fold of dataset\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "[0] training loss=0.7035 Time in 0 m 6 s\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "[10] training loss=0.1596 Time in 0 m 4 s\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "[20] training loss=0.1990 Time in 0 m 2 s\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "[30] training loss=0.1836 Time in 0 m 4 s\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "[40] training loss=0.1478 Time in 0 m 3 s\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "[50] training loss=0.1633 Time in 0 m 3 s\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "[60] training loss=0.1365 Time in 0 m 2 s\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "[70] training loss=0.1561 Time in 0 m 5 s\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "[80] training loss=0.1535 Time in 0 m 2 s\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "[90] training loss=0.1652 Time in 0 m 3 s\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "[100] training loss=0.1258 Time in 0 m 2 s\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "[110] training loss=0.1565 Time in 0 m 5 s\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "[120] training loss=0.1421 Time in 0 m 6 s\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "[130] training loss=0.1514 Time in 0 m 1 s\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "[140] training loss=0.1231 Time in 0 m 7 s\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "[150] training loss=0.1474 Time in 0 m 4 s\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "[160] training loss=0.1318 Time in 0 m 1 s\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "[170] training loss=0.1521 Time in 0 m 6 s\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "[180] training loss=0.1508 Time in 0 m 3 s\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "[190] training loss=0.1832 Time in 0 m 3 s\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n",
      "torch.Size([4, 2048, 1, 1]) torch.Size([4]) torch.Size([4, 12, 1, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8be684d4944a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbestModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpDecayOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-089173d16b85>\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# Iterate over data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataLoaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mclass_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_batch\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "bestModel = Train(model, criterion, optimizer, expDecayOptimizer, nEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
